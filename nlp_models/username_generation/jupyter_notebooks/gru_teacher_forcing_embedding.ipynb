{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My RNN Language Model implementation in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'*': 0, '<': 1, '>': 2, '\\n': 3, '0': 4, '1': 5, '2': 6, '3': 7, '4': 8, '5': 9, '6': 10, '7': 11, '8': 12, '9': 13, 'a': 14, 'b': 15, 'c': 16, 'd': 17, 'e': 18, 'f': 19, 'g': 20, 'h': 21, 'i': 22, 'j': 23, 'k': 24, 'l': 25, 'm': 26, 'n': 27, 'o': 28, 'p': 29, 'q': 30, 'r': 31, 's': 32, 't': 33, 'u': 34, 'v': 35, 'w': 36, 'x': 37, 'y': 38, 'z': 39}\n",
      "Number of characters: 401244\n",
      "Number of unique characters: 40\n",
      "Longest word: rabbitsreviews\n",
      "Length of longest word: 14\n"
     ]
    }
   ],
   "source": [
    "with open('../datasets/username_dataset.txt', 'r') as file:\n",
    "    data = file.readlines()\n",
    "    \n",
    "data = [example.strip().lower() for example in data]\n",
    "\n",
    "with open('../datasets/username_dataset.txt', 'r') as file:\n",
    "    data_str = file.read().lower()\n",
    "\n",
    "vocab = list(set(data_str))\n",
    "vocab.sort()\n",
    "\n",
    "vocab.insert(0, '>') # End token: <end>\n",
    "vocab.insert(0, '<') # Start token: <start>\n",
    "vocab.insert(0, '*') # Padding\n",
    "\n",
    "char_to_index = {ch: i for i, ch in enumerate(vocab)}\n",
    "index_to_char = {i: ch for i, ch in enumerate(vocab)}\n",
    "\n",
    "print(char_to_index)\n",
    "\n",
    "longest_word = max(data, key=len)\n",
    "\n",
    "print(f\"Number of characters: {len(data_str)}\")\n",
    "print(f\"Number of unique characters: {len(vocab)}\")\n",
    "print(f\"Longest word: {longest_word}\")\n",
    "print(f\"Length of longest word: {len(longest_word)}\") # Needed information to know what length to pad the usernames to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '*' :   0,\n",
      "  '<' :   1,\n",
      "  '>' :   2,\n",
      "  '\\n':   3,\n",
      "  '0' :   4,\n",
      "  '1' :   5,\n",
      "  '2' :   6,\n",
      "  '3' :   7,\n",
      "  '4' :   8,\n",
      "  '5' :   9,\n",
      "  '6' :  10,\n",
      "  '7' :  11,\n",
      "  '8' :  12,\n",
      "  '9' :  13,\n",
      "  'a' :  14,\n",
      "  'b' :  15,\n",
      "  'c' :  16,\n",
      "  'd' :  17,\n",
      "  'e' :  18,\n",
      "  'f' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def print_mapping(mapping):\n",
    "    print('{')\n",
    "    for char, _ in zip(mapping, range(20)):\n",
    "        print('  {:4s}: {:3d},'.format(repr(char), mapping[char]))\n",
    "    print('  ...\\n}')\n",
    "    \n",
    "print_mapping(char_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54037, 15)\n",
      "(54037, 15)\n"
     ]
    }
   ],
   "source": [
    "def prepare_dataset(data, username_length):\n",
    "    \"\"\"Adds <start> and <end> tokens and pads the usernames.\"\"\"\n",
    "    data_X = []\n",
    "    data_Y = []\n",
    "    for username in data:\n",
    "        pad = \"*\" * (username_length - len(username))\n",
    "        X = np.array([char_to_index[char] for char in f\"<{username}{pad}\"]) #.reshape((username_length + 1, 1))\n",
    "        Y = np.array([char_to_index[char] for char in f\"{username}>{pad}\"]) #.reshape((username_length + 1, 1))\n",
    "        data_X.append(X)\n",
    "        data_Y.append(Y)\n",
    "    \n",
    "\n",
    "    return (np.array(data_X), np.array(data_Y))\n",
    "\n",
    "data = prepare_dataset(data, len(longest_word))\n",
    "\n",
    "print(data[0].shape)\n",
    "print(data[1].shape)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  '<info**********'\n",
      "Target data: 'info>**********'\n",
      "Input data:  [ 1 22 27 19 28  0  0  0  0  0  0  0  0  0  0]\n",
      "Target data: [22 27 19 28  2  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print('Input data: ', repr(''.join([index_to_char[i] for i in input_example.numpy()])))\n",
    "    print('Target data:', repr(''.join([index_to_char[i] for i in target_example.numpy()])))\n",
    "    \n",
    "for input_example, target_example in dataset.take(1):\n",
    "    print('Input data: ', input_example.numpy())\n",
    "    print('Target data:', target_example.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((128, 15), (128, 15)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 10000\n",
    "EPOCHS = 100\n",
    "VOCAB_SIZE = len(vocab)\n",
    "RNN_UNITS = 512\n",
    "EMBEDDING_DIM = 256\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, rnn_units, batch_size, embedding_dim, stateful=False):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Masking(mask_value=0, batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                             return_sequences=True,\n",
    "                             stateful=stateful,\n",
    "                             recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size, activation=tf.nn.softmax)])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocab_size = VOCAB_SIZE,\n",
    "    rnn_units=RNN_UNITS,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (128, None)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (128, None, 256)          10240     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (128, None, 512)          1182720   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (128, None, 40)           20520     \n",
      "=================================================================\n",
      "Total params: 1,213,480\n",
      "Trainable params: 1,213,480\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                               min_delta=0,\n",
    "                                               patience=5,\n",
    "                                               verbose=0,\n",
    "                                               mode='auto',\n",
    "                                               baseline=None,\n",
    "                                               restore_best_weights=True)\n",
    "# MAKES NO SENSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "422/422 [==============================] - 77s 182ms/step - loss: 1.3524\n",
      "Epoch 2/100\n",
      "422/422 [==============================] - 71s 167ms/step - loss: 1.1823\n",
      "Epoch 3/100\n",
      "422/422 [==============================] - 70s 165ms/step - loss: 1.1423\n",
      "Epoch 4/100\n",
      "422/422 [==============================] - 70s 166ms/step - loss: 1.1050\n",
      "Epoch 5/100\n",
      "422/422 [==============================] - 72s 171ms/step - loss: 1.0717\n",
      "Epoch 6/100\n",
      "422/422 [==============================] - 61s 143ms/step - loss: 1.0428\n",
      "Epoch 7/100\n",
      "422/422 [==============================] - 59s 140ms/step - loss: 1.0167\n",
      "Epoch 8/100\n",
      "422/422 [==============================] - 60s 141ms/step - loss: 0.9927\n",
      "Epoch 9/100\n",
      "422/422 [==============================] - 60s 143ms/step - loss: 0.9714\n",
      "Epoch 10/100\n",
      "422/422 [==============================] - 60s 141ms/step - loss: 0.9516\n",
      "Epoch 11/100\n",
      "422/422 [==============================] - 60s 142ms/step - loss: 0.9336\n",
      "Epoch 12/100\n",
      "422/422 [==============================] - 60s 142ms/step - loss: 0.9177\n",
      "Epoch 13/100\n",
      "422/422 [==============================] - 60s 142ms/step - loss: 0.9034\n",
      "Epoch 14/100\n",
      "422/422 [==============================] - 60s 142ms/step - loss: 0.8908\n",
      "Epoch 15/100\n",
      "422/422 [==============================] - 60s 143ms/step - loss: 0.8795\n",
      "Epoch 16/100\n",
      "422/422 [==============================] - 60s 143ms/step - loss: 0.8695\n",
      "Epoch 17/100\n",
      "422/422 [==============================] - 60s 143ms/step - loss: 0.8611\n",
      "Epoch 18/100\n",
      "422/422 [==============================] - 61s 143ms/step - loss: 0.8532\n",
      "Epoch 19/100\n",
      "422/422 [==============================] - 61s 144ms/step - loss: 0.8463\n",
      "Epoch 20/100\n",
      "422/422 [==============================] - 61s 144ms/step - loss: 0.8406\n",
      "Epoch 21/100\n",
      "422/422 [==============================] - 61s 144ms/step - loss: 0.8349\n",
      "Epoch 22/100\n",
      "422/422 [==============================] - 62s 146ms/step - loss: 0.8304\n",
      "Epoch 23/100\n",
      "422/422 [==============================] - 62s 146ms/step - loss: 0.8263\n",
      "Epoch 24/100\n",
      "422/422 [==============================] - 62s 146ms/step - loss: 0.8226\n",
      "Epoch 25/100\n",
      "422/422 [==============================] - 62s 146ms/step - loss: 0.8186\n",
      "Epoch 26/100\n",
      "422/422 [==============================] - 62s 147ms/step - loss: 0.8163\n",
      "Epoch 27/100\n",
      "422/422 [==============================] - 62s 147ms/step - loss: 0.8128\n",
      "Epoch 28/100\n",
      "422/422 [==============================] - 62s 148ms/step - loss: 0.8104\n",
      "Epoch 29/100\n",
      "422/422 [==============================] - 62s 148ms/step - loss: 0.8080\n",
      "Epoch 30/100\n",
      "422/422 [==============================] - 63s 149ms/step - loss: 0.8058\n",
      "Epoch 31/100\n",
      "422/422 [==============================] - 63s 149ms/step - loss: 0.8034\n",
      "Epoch 32/100\n",
      "422/422 [==============================] - 63s 150ms/step - loss: 0.8013\n",
      "Epoch 33/100\n",
      "422/422 [==============================] - 63s 150ms/step - loss: 0.7994\n",
      "Epoch 34/100\n",
      "422/422 [==============================] - 64s 152ms/step - loss: 0.7980\n",
      "Epoch 35/100\n",
      "422/422 [==============================] - 64s 152ms/step - loss: 0.7964\n",
      "Epoch 36/100\n",
      "422/422 [==============================] - 65s 155ms/step - loss: 0.7951\n",
      "Epoch 37/100\n",
      "422/422 [==============================] - 65s 153ms/step - loss: 0.7936\n",
      "Epoch 38/100\n",
      "422/422 [==============================] - 65s 154ms/step - loss: 0.7924\n",
      "Epoch 39/100\n",
      "422/422 [==============================] - 65s 155ms/step - loss: 0.7912\n",
      "Epoch 40/100\n",
      "422/422 [==============================] - 66s 156ms/step - loss: 0.7896\n",
      "Epoch 41/100\n",
      "422/422 [==============================] - 69s 163ms/step - loss: 0.7887\n",
      "Epoch 42/100\n",
      "422/422 [==============================] - 67s 158ms/step - loss: 0.7877\n",
      "Epoch 43/100\n",
      "422/422 [==============================] - 67s 159ms/step - loss: 0.7865\n",
      "Epoch 44/100\n",
      "422/422 [==============================] - 67s 160ms/step - loss: 0.7859\n",
      "Epoch 45/100\n",
      "422/422 [==============================] - 68s 161ms/step - loss: 0.7850\n",
      "Epoch 46/100\n",
      "422/422 [==============================] - 68s 161ms/step - loss: 0.7839\n",
      "Epoch 47/100\n",
      "422/422 [==============================] - 69s 163ms/step - loss: 0.7834\n",
      "Epoch 48/100\n",
      "422/422 [==============================] - 69s 163ms/step - loss: 0.7820\n",
      "Epoch 49/100\n",
      "422/422 [==============================] - 69s 164ms/step - loss: 0.7816\n",
      "Epoch 50/100\n",
      "422/422 [==============================] - 70s 165ms/step - loss: 0.7801\n",
      "Epoch 51/100\n",
      "422/422 [==============================] - 71s 169ms/step - loss: 0.7800\n",
      "Epoch 52/100\n",
      " 24/422 [>.............................] - ETA: 1:08 - loss: 0.7587"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-495d731eb21c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(dataset, epochs=EPOCHS, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('../weights/gru_model_embedding_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(VOCAB_SIZE, RNN_UNITS, 1, EMBEDDING_DIM, stateful=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../weights/gru_model_embedding_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_usernames(model):\n",
    "    num_generate = 7\n",
    "    generated_usernames = []\n",
    "\n",
    "    for i in range(num_generate):\n",
    "        model.reset_states()\n",
    "        input_eval = np.array([char_to_index['<']]).reshape((1, 1))  # We start with the '<start>' token\n",
    "        generated_username = []\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            predictions = model.predict(input_eval)\n",
    "            predictions = tf.squeeze(predictions)\n",
    "\n",
    "            predicted_id = np.random.choice(range(40), p=predictions.numpy())\n",
    "            # predicted_id = np.argmax(predictions)\n",
    "\n",
    "            input_eval = np.array([predicted_id]).reshape((1, 1))\n",
    "            \n",
    "            done = index_to_char[predicted_id] in ['>', '*']\n",
    "            \n",
    "            if not done:\n",
    "                generated_username.append(index_to_char[predicted_id])\n",
    "        generated_usernames.append(\"\".join(generated_username))\n",
    "\n",
    "    return generated_usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['casanova', 'lammer', 'breaks', 'recover', 'hinashid', 'unset', 'bluey']\n",
      "['barry5', 'wilkid', 'burhad', 'tran', 'freew', 'jamie', 'fixit']\n",
      "['irishra', 'country', 'steve1', 'dave', 'hammy', 'lange', 'lumber']\n",
      "['starwars', 'garion', 'delray', 'tommyt', 'esquire', 'mand', 'binno']\n",
      "['bryan', 'stephen', 'sukrate', 'anthonyl', 'brahis', 'conaus', 'chrisb']\n",
      "['marko', 'sheila', 'orlion', 'thomas28', 'brian6', 'fresh', 'lacey']\n",
      "['abrico', 'metallic', 'bed', 'chris22', 'tigerboy', 'spawnnn', 'london']\n",
      "['bike', 'heller', 'leon', 'bath', 'westleherf', 'timoteo', 'gero']\n",
      "['rasmus', 'odonnell', 'fucker', 'clhall', 'alfhern', 'bubba01', 'myhope']\n",
      "['giovane', 'mercy', 'corona', 'slaves', 'marklee', 'porny', 'mikee']\n",
      "['johnnys', 'disbite', 'slloyd', 'drew', 'condem', 'blueey', 'afrodite']\n",
      "['bmiller', 'boout', 'gordo', 'ericc', 'greg55', 'oldgod', 'david']\n",
      "['ddave', 'vera', 'smegman', 'perfecto', 'rebel1', 'hardup', 'henry']\n",
      "['arron', 'toastie', 'darkboy', 'srilank', 'octavia', 'evildave', 'free']\n",
      "['calvin', 'craiger', 'sack', 'trackman', 'timote', 'invis', 'fanman']\n",
      "['smirnoff', 'breast', 'magedam', 'shoole', 'raju', 'piggy50', 'peterpan']\n",
      "['david15', 'gattino', 'tilly', 'racere', 'therrave', 'peterk', 'bamble']\n",
      "['thorns', 'theman', 'eric1', 'zorros', 'rich', 'hhawaii', 'tank']\n",
      "['elvis', 'raphael', 'bandit1', 'briz24', 'ford', 'mudder', 'kiffer']\n",
      "['dokliger', 'steam', 'jackin', 'hudson', 'rambot8', 'james11', 'bando']\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    generated_usernames = generate_usernames(model)\n",
    "    print(generated_usernames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
